{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6028473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spal0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265610, 302)\n",
      "(66403, 302)\n",
      "Model accuracy: 52.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spal0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342280, 302)\n",
      "(85570, 302)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spal0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256000, 302)\n",
      "(64000, 302)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spal0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188541, 302)\n",
      "(47135, 302)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "csvFile=open('newfrequency300.csv', 'rt')\n",
    "csvReader=csv.reader(csvFile)\n",
    "mydict={row[1]: int(row[0]) for row in csvReader}\n",
    "\n",
    "y=[]\n",
    "with open ('PJFinaltest.csv', 'rt') as f:\n",
    "\treader=csv.reader(f)\n",
    "\tcorpus=[rows[0] for rows in reader]\n",
    "\n",
    "with open ('PJFinaltest.csv', 'rt') as f:\n",
    "\tcsvReader1=csv.reader(f)\n",
    "\tfor rows in csvReader1:\n",
    "\t\ty.append([int(rows[1])])\n",
    "vectorizer=TfidfVectorizer(vocabulary=mydict,min_df=1)\n",
    "x=vectorizer.fit_transform(corpus).toarray()\n",
    "result=np.append(x,y,axis=1) m\n",
    "X=pandas.DataFrame(result)\n",
    "model=GaussianNB()\n",
    "train = X.sample(frac=0.8, random_state=1)\n",
    "test=X.drop(train.index)\n",
    "y_train=train[301]\n",
    "y_test=test[301]\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "xtrain=train.drop(301,axis=1)\n",
    "xtest=test.drop(301,axis=1)\n",
    "model.fit(xtrain,y_train)\n",
    "pickle.dump(model, open('BNPJFinal.sav', 'wb'))\n",
    "# y_pred = model.predict(xtest)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
    "del result\n",
    "\n",
    "y=[]\n",
    "with open ('IEFinaltest.csv', 'rt') as f:\n",
    "\treader=csv.reader(f)\n",
    "\tcorpus=[rows[0] for rows in reader]\n",
    "\n",
    "with open ('IEFinaltest.csv', 'rt') as f:\n",
    "\tcsvReader1=csv.reader(f)\n",
    "\tfor rows in csvReader1:\n",
    "\t\ty.append([int(rows[1])])\n",
    "vectorizer=TfidfVectorizer(vocabulary=mydict,min_df=1)\n",
    "x=vectorizer.fit_transform(corpus).toarray()\n",
    "result=np.append(x,y,axis=1)\n",
    "X=pandas.DataFrame(result)\n",
    "model=GaussianNB()\n",
    "train = X.sample(frac=0.8, random_state=1)\n",
    "test=X.drop(train.index)\n",
    "y_train=train[301]\n",
    "y_test=test[301]\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "xtrain=train.drop(301,axis=1)\n",
    "xtest=test.drop(301,axis=1)\n",
    "model.fit(xtrain,y_train)\n",
    "pickle.dump(model, open('BNIEFinal.sav', 'wb'))\n",
    "del result\n",
    "\n",
    "y=[]\n",
    "with open ('TFFinaltest.csv', 'rt') as f:\n",
    "\treader=csv.reader(f)\n",
    "\tcorpus=[rows[0] for rows in reader]\n",
    "\n",
    "with open ('TFFinaltest.csv', 'rt') as f:\n",
    "\tcsvReader1=csv.reader(f)\n",
    "\tfor rows in csvReader1:\n",
    "\t\ty.append([int(rows[1])])\n",
    "vectorizer=TfidfVectorizer(vocabulary=mydict,min_df=1)\n",
    "x=vectorizer.fit_transform(corpus).toarray()\n",
    "result=np.append(x,y,axis=1)\n",
    "X=pandas.DataFrame(result)\n",
    "model=GaussianNB()\n",
    "train = X.sample(frac=0.8, random_state=1)\n",
    "test=X.drop(train.index)\n",
    "y_train=train[301]\n",
    "y_test=test[301]\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "xtrain=train.drop(301,axis=1)\n",
    "xtest=test.drop(301,axis=1)\n",
    "model.fit(xtrain,y_train)\n",
    "pickle.dump(model, open('BNTFFinal.sav', 'wb'))\n",
    "del result\n",
    "\n",
    "y=[]\n",
    "with open ('SNFinaltest.csv', 'rt') as f:\n",
    "\treader=csv.reader(f)\n",
    "\tcorpus=[rows[0] for rows in reader]\n",
    "\n",
    "with open ('SNFinaltest.csv', 'rt') as f:\n",
    "\tcsvReader1=csv.reader(f)\n",
    "\tfor rows in csvReader1:\n",
    "\t\ty.append([int(rows[1])])\n",
    "vectorizer=TfidfVectorizer(vocabulary=mydict,min_df=1)\n",
    "x=vectorizer.fit_transform(corpus).toarray()\n",
    "result=np.append(x,y,axis=1)\n",
    "X=pandas.DataFrame(result)\n",
    "model=GaussianNB()\n",
    "train = X.sample(frac=0.8, random_state=1)\n",
    "test=X.drop(train.index)\n",
    "y_train=train[301]\n",
    "y_test=test[301]\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "xtrain=train.drop(301,axis=1)\n",
    "xtest=test.drop(301,axis=1)\n",
    "model.fit(xtrain,y_train)\n",
    "pickle.dump(model, open('BNSNFinal.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41de6460-42eb-4d13-9631-4960165f1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ntscraper import Nitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39857b3b-3639-4118-93bc-01334b57a6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|██████████| 77/77 [08:12<00:00,  6.40s/it]\n"
     ]
    }
   ],
   "source": [
    "# scraper = Nitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80244e93-2cdd-4a4f-8b5c-c0571974f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# import csv\n",
    "# import sys\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import pandas as pd\n",
    "# import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe20752f-be29-421e-975e-3946dcd70565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19-May-24 12:25:17 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "19-May-24 12:25:23 - Current stats for elonmusk: 20 tweets, 0 threads...\n",
      "19-May-24 12:25:28 - Current stats for elonmusk: 40 tweets, 0 threads...\n",
      "19-May-24 12:25:32 - Current stats for elonmusk: 50 tweets, 0 threads...\n",
      "[(0.0, 29)]\n",
      "[(0.0, 29)]\n",
      "[(0.0, 29)]\n",
      "[(0.0, 25)]\n",
      "ENFJ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spal0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tweetList =[]\n",
    "# def getTweets(name):\n",
    "#  csvFile = open('user.csv', 'a', newline='')\n",
    "#  csvWriter = csv.writer(csvFile)\n",
    "#  tweets = scraper.get_tweets(name,mode=\"user\",number=50)\n",
    "#  for tweet in tweets['tweets']:\n",
    "#     data = (tweet['text'])\n",
    "#     tweetList.append(data)\n",
    "\n",
    "\n",
    "\n",
    "# username=input(\"Please Enter Twitter Account handle: \")\n",
    "# getTweets(username)\n",
    "# with open('user.csv','rt') as f:\n",
    "# \tcsvReader=csv.reader(f)\n",
    "# with open('newfrequency300.csv','rt') as f:\n",
    "# \tcsvReader=csv.reader(f)\n",
    "# \tmydict={rows[1]: int(rows[0]) for rows in csvReader}\n",
    "\n",
    "# if len(tweetList) > 0:\n",
    "#     vectorizer = TfidfVectorizer(vocabulary=mydict, min_df=1)\n",
    "#     x = vectorizer.fit_transform(tweetList).toarray()\n",
    "#     df = pd.DataFrame(x)\n",
    "# else:\n",
    "#     print(\"No tweets found. Check your data loading process.\")\n",
    "#     sys.exit()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# model_IE = pickle.load(open(\"BNIEFinal.sav\", 'rb'))\n",
    "# model_SN = pickle.load(open(\"BNSNFinal.sav\", 'rb'))\n",
    "# model_TF = pickle.load(open('BNTFFinal.sav', 'rb'))\n",
    "# model_PJ = pickle.load(open('BNPJFinal.sav', 'rb'))\n",
    "\n",
    "# answer=[]\n",
    "# IE=model_IE.predict(df)\n",
    "# SN=model_SN.predict(df)\n",
    "# TF=model_TF.predict(df)\n",
    "# PJ=model_PJ.predict(df)\n",
    "\n",
    "\n",
    "# b = Counter(IE)\n",
    "# value=b.most_common(1)\n",
    "# print(value)\n",
    "# if value[0][0] == 1.0:\n",
    "# \tanswer.append(\"I\")\n",
    "# else:\n",
    "# \tanswer.append(\"E\")\n",
    "\n",
    "# b = Counter(SN)\n",
    "# value=b.most_common(1)\n",
    "# print(value)\n",
    "# if value[0][0] == 1.0:\n",
    "# \tanswer.append(\"S\")\n",
    "# else:\n",
    "# \tanswer.append(\"N\")\n",
    "\n",
    "# b = Counter(TF)\n",
    "# value=b.most_common(1)\n",
    "# print(value)\n",
    "# if value[0][0] == 1:\n",
    "# \tanswer.append(\"T\")\n",
    "# else:\n",
    "# \tanswer.append(\"F\")\n",
    "\n",
    "# b = Counter(PJ)\n",
    "\n",
    "# value=b.most_common(1)\n",
    "# print(value)\n",
    "# if value[0][0] == 1:\n",
    "# \tanswer.append(\"P\")\n",
    "# else:\n",
    "# \tanswer.append(\"J\")\n",
    "# mbti=\"\".join(answer)\n",
    " \n",
    "# print(mbti)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
